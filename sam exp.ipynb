{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b59bec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam import SAM\n",
    "from utility.step_lr import StepLR\n",
    "from wide_res_net import WideResNet\n",
    "from utility.initialize import initialize\n",
    "from utility.step_lr import StepLR\n",
    "from utility.bypass_bn import enable_running_stats, disable_running_stats\n",
    "from smooth_cross_entropy import smooth_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54fdfcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.utils\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35310b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dsets.MNIST(root='data/',\n",
    "                         train=True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "\n",
    "test_data = dsets.MNIST(root='data/',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65275485",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6bea1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 5), #[100,16,24,24]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 5),#[100,32,20,20]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),#100,32,10,10\n",
    "            nn.Conv2d(32, 64, 5),#100,64,6,6\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)#100,64,3,3 -> 여기서 batch 빼고 나머지 64*3*3\n",
    "        )\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*3*3, 100), #여기서 64*3*3 -> 100\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10)#100 -> 10\n",
    "        )       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.conv_layer(x)\n",
    "        out = out.view(-1,64*3*3)\n",
    "        out = self.fc_layer(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "733c9e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da634d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_optimizer = torch.optim.SGD\n",
    "optimizer = SAM(model.parameters(), base_optimizer, rho=2.0, adaptive=True, lr=0.1, momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a55decca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer._grad_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b85bb235",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = StepLR(optimizer,0.1, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b6a13cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_data,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3cd0761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test images: 11.000000 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    model.train()\n",
    "\n",
    "    #for batch in train_data.train:\n",
    "    for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "        inputs = batch_images.to(device)\n",
    "        targets = batch_labels.to(device) \n",
    "        \n",
    "        # first forward-backward step\n",
    "        enable_running_stats(model)\n",
    "        predictions = model(inputs)\n",
    "#         loss = smooth_crossentropy(predictions, targets, smoothing=0.1)\n",
    "#         loss.mean().backward()\n",
    "        loss = nn.CrossEntropyLoss()(predictions, targets)\n",
    "        loss.backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "\n",
    "        # second forward-backward step\n",
    "        disable_running_stats(model)\n",
    "        #smooth_crossentropy(model(inputs), targets, smoothing=0.1).mean().backward()\n",
    "        nn.CrossEntropyLoss()(model(inputs), targets).backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct = torch.argmax(predictions.data, 1) == targets\n",
    "            #log(model, loss.cpu(), correct.cpu(), scheduler.lr())\n",
    "            scheduler(epoch)\n",
    "\n",
    "    model.eval()\n",
    "  #  log.eval(len_dataset=len(dataset.test))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (batch_images, batch_labels) in enumerate(test_loader):\n",
    "        #for batch in dataset.test:\n",
    "            inputs = batch_images.to(device)\n",
    "            targets = batch_labels.to(device) \n",
    "\n",
    "            predictions = model(inputs)\n",
    "#            loss = smooth_crossentropy(predictions, targets)\n",
    "            correct = torch.argmax(predictions, 1) == targets\n",
    "          #  log(model, loss.cpu(), correct.cpu())\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i, (batch_images, batch_labels) in enumerate(test_loader):\n",
    "    #for batch in dataset.test:\n",
    "        inputs = batch_images.to(device)\n",
    "        targets = batch_labels.to(device) \n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.cuda()).sum()\n",
    "    \n",
    "print('Accuracy of test images: %f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a9fe353",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c468b04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test images: 16.220000 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    model.train()\n",
    "\n",
    "    #for batch in train_data.train:\n",
    "    for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "        X = batch_images.cuda()\n",
    "        Y = batch_labels.cuda()\n",
    "\n",
    "        predictions = model(X)\n",
    "        #loss = smooth_crossentropy(predictions, targets, smoothing=0.1)\n",
    "        loss = nn.CrossEntropyLoss()(predictions, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    \n",
    "    images = images.cuda()\n",
    "    outputs = model(images)\n",
    "    \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels.cuda()).sum()\n",
    "    \n",
    "print('Accuracy of test images: %f %%' % (100 * float(correct) / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
